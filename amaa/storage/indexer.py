"""
AMAA v0.4 - File Indexer
LlamaIndex ê¸°ë°˜ íŒŒì¼ ì¸ë±ì„œ (ìì—°ì–´ ê²€ìƒ‰ ì§€ì›)
"""

from pathlib import Path
from typing import Optional, List, Dict, Any


class FileIndexer:
    """
    LlamaIndex ê¸°ë°˜ íŒŒì¼ ì¸ë±ì„œ
    
    ì •ë¦¬ëœ íŒŒì¼ë“¤ì„ ì¸ë±ì‹±í•˜ì—¬ ìì—°ì–´ ê²€ìƒ‰ ì§€ì›
    
    Usage:
        indexer = FileIndexer(index_path="~/.amaa/index")
        indexer.index_directory("/path/to/organized")
        results = indexer.search("í”„ë¡œì íŠ¸ ê´€ë ¨ PDF ë¬¸ì„œ")
    """
    
    def __init__(self, index_path: str = "~/.amaa/index"):
        self.index_path = Path(index_path).expanduser()
        self.index_path.mkdir(parents=True, exist_ok=True)
        
        self._index = None
        self._llama_available = self._check_llama_index()
    
    def _check_llama_index(self) -> bool:
        """LlamaIndex ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
        try:
            from llama_index.core import SimpleDirectoryReader, VectorStoreIndex
            return True
        except ImportError:
            return False
    
    def index_directory(self, dir_path: str, 
                        recursive: bool = True) -> Dict[str, Any]:
        """
        ë””ë ‰í† ë¦¬ ì¸ë±ì‹±
        
        Args:
            dir_path: ì¸ë±ì‹±í•  ë””ë ‰í† ë¦¬
            recursive: ì¬ê·€ ì—¬ë¶€
            
        Returns:
            Dict: ì¸ë±ì‹± ê²°ê³¼
        """
        if not self._llama_available:
            return {
                'status': 'error',
                'message': 'LlamaIndex not installed. Run: pip install llama-index'
            }
        
        try:
            from llama_index.core import SimpleDirectoryReader, VectorStoreIndex
            from llama_index.core import Settings
            
            # ë¬¸ì„œ ë¡œë“œ
            reader = SimpleDirectoryReader(
                input_dir=dir_path,
                recursive=recursive,
                exclude_hidden=True
            )
            documents = reader.load_data()
            
            # ì¸ë±ìŠ¤ ìƒì„±
            self._index = VectorStoreIndex.from_documents(documents)
            
            # ì¸ë±ìŠ¤ ì €ì¥
            self._index.storage_context.persist(str(self.index_path))
            
            return {
                'status': 'success',
                'documents_indexed': len(documents),
                'index_path': str(self.index_path)
            }
            
        except Exception as e:
            return {
                'status': 'error',
                'message': str(e)
            }
    
    def load_index(self) -> bool:
        """ì €ì¥ëœ ì¸ë±ìŠ¤ ë¡œë“œ"""
        if not self._llama_available:
            return False
        
        try:
            from llama_index.core import StorageContext, load_index_from_storage
            
            storage_context = StorageContext.from_defaults(
                persist_dir=str(self.index_path)
            )
            self._index = load_index_from_storage(storage_context)
            return True
            
        except Exception:
            return False
    
    def search(self, query: str, top_k: int = 5) -> List[Dict[str, Any]]:
        """
        ìì—°ì–´ ê²€ìƒ‰
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            top_k: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜
            
        Returns:
            List[Dict]: ê²€ìƒ‰ ê²°ê³¼
        """
        if not self._llama_available:
            return [{'error': 'LlamaIndex not installed'}]
        
        if self._index is None:
            if not self.load_index():
                return [{'error': 'No index available'}]
        
        try:
            query_engine = self._index.as_query_engine(similarity_top_k=top_k)
            response = query_engine.query(query)
            
            results = []
            for node in response.source_nodes:
                results.append({
                    'content': node.text[:500],
                    'score': node.score,
                    'metadata': node.metadata
                })
            
            return results
            
        except Exception as e:
            return [{'error': str(e)}]
    
    def is_available(self) -> bool:
        """ì¸ë±ì„œ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€"""
        return self._llama_available


if __name__ == "__main__":
    import sys
    
    print("ğŸ“š AMAA File Indexer Test")
    print("=" * 50)
    
    indexer = FileIndexer()
    
    if not indexer.is_available():
        print("âš ï¸ LlamaIndex not installed")
        print("   Run: pip install llama-index llama-index-embeddings-huggingface")
    else:
        print("âœ… LlamaIndex available")
        
        if len(sys.argv) > 1:
            path = sys.argv[1]
            print(f"\nğŸ“ Indexing: {path}")
            result = indexer.index_directory(path)
            print(f"Result: {result}")
