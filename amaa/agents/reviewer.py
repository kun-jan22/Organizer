"""
AMAA v0.4 - Reviewer Agent
ì¡°ì§í™” ê²°ê³¼ ê²€í†  ë° í”¼ë“œë°± ì—ì´ì „íŠ¸

Multi-Agent Systemì˜ ê²€í†  ë‹´ë‹¹
- ì¡°ì§í™” ê²°ê³¼ í’ˆì§ˆ í‰ê°€
- ê°œì„  ì œì•ˆ ìƒì„±
- í•™ìŠµ í”¼ë“œë°± ìˆ˜ì§‘
"""

from pathlib import Path
from datetime import datetime
from typing import Optional, List, Dict, Any
from dataclasses import dataclass, field

from ..core.perceiver import OllamaClient


@dataclass
class ReviewItem:
    """ê²€í†  í•­ëª©"""
    file_path: str
    original_path: str
    action_taken: str
    is_correct: Optional[bool] = None
    user_feedback: Optional[str] = None
    suggested_correction: Optional[str] = None
    timestamp: str = ""
    
    def to_dict(self) -> dict:
        return {
            'file_path': self.file_path,
            'original_path': self.original_path,
            'action_taken': self.action_taken,
            'is_correct': self.is_correct,
            'user_feedback': self.user_feedback,
            'suggested_correction': self.suggested_correction,
            'timestamp': self.timestamp,
        }


@dataclass
class ReviewReport:
    """ê²€í†  ë³´ê³ ì„œ"""
    session_id: str
    reviewed_at: str
    total_items: int = 0
    correct_count: int = 0
    incorrect_count: int = 0
    pending_count: int = 0
    accuracy_rate: float = 0.0
    items: List[ReviewItem] = field(default_factory=list)
    recommendations: List[str] = field(default_factory=list)
    
    def to_dict(self) -> dict:
        return {
            'session_id': self.session_id,
            'reviewed_at': self.reviewed_at,
            'total_items': self.total_items,
            'correct_count': self.correct_count,
            'incorrect_count': self.incorrect_count,
            'pending_count': self.pending_count,
            'accuracy_rate': self.accuracy_rate,
            'items': [i.to_dict() for i in self.items],
            'recommendations': self.recommendations,
        }


class ReviewerAgent:
    """
    ì¡°ì§í™” ê²°ê³¼ ê²€í†  ì—ì´ì „íŠ¸
    
    ì‹¤í–‰ëœ ì¡°ì§í™” ê²°ê³¼ë¥¼ í‰ê°€í•˜ê³  í”¼ë“œë°± ìˆ˜ì§‘
    
    Usage:
        reviewer = ReviewerAgent(config)
        report = reviewer.create_review(session)
        
        # ì‚¬ìš©ì í”¼ë“œë°± ìˆ˜ì§‘
        reviewer.mark_correct(report.items[0])
        reviewer.mark_incorrect(report.items[1], "Should be in Projects folder")
        
        # ë³´ê³ ì„œ ìƒì„±
        summary = reviewer.generate_summary(report)
    """
    
    def __init__(self, config=None):
        """
        Args:
            config: AMAA Config ê°ì²´
        """
        self.config = config
        
        # LLM í´ë¼ì´ì–¸íŠ¸ (í”¼ë“œë°± ë¶„ì„ìš©)
        if config:
            self.ollama = OllamaClient(
                base_url=config.ollama.base_url,
                model=config.ollama.model
            )
        else:
            self.ollama = OllamaClient()
        
        # í”¼ë“œë°± ì €ì¥ì†Œ
        self._feedback_history: List[ReviewItem] = []
    
    def create_review(self, session_data: Dict[str, Any]) -> ReviewReport:
        """
        ì„¸ì…˜ ê²°ê³¼ë¡œë¶€í„° ê²€í†  ë³´ê³ ì„œ ìƒì„±
        
        Args:
            session_data: ì¡°ì§í™” ì„¸ì…˜ ë°ì´í„°
            
        Returns:
            ReviewReport: ê²€í†  ë³´ê³ ì„œ
        """
        report = ReviewReport(
            session_id=session_data.get('session_id', 'unknown'),
            reviewed_at=datetime.now().isoformat()
        )
        
        changes = session_data.get('changes', [])
        
        for change in changes:
            if change.get('executed'):
                item = ReviewItem(
                    file_path=change.get('destination_path', ''),
                    original_path=change.get('source_path', ''),
                    action_taken=change.get('action', 'unknown'),
                    timestamp=datetime.now().isoformat()
                )
                report.items.append(item)
                report.total_items += 1
                report.pending_count += 1
        
        return report
    
    def mark_correct(self, item: ReviewItem) -> None:
        """í•­ëª©ì„ ì˜¬ë°”ë¦„ìœ¼ë¡œ í‘œì‹œ"""
        item.is_correct = True
        self._feedback_history.append(item)
    
    def mark_incorrect(self, item: ReviewItem, 
                       feedback: str,
                       correction: Optional[str] = None) -> None:
        """í•­ëª©ì„ ì˜ëª»ë¨ìœ¼ë¡œ í‘œì‹œ"""
        item.is_correct = False
        item.user_feedback = feedback
        item.suggested_correction = correction
        self._feedback_history.append(item)
    
    def update_report_stats(self, report: ReviewReport) -> ReviewReport:
        """ë³´ê³ ì„œ í†µê³„ ì—…ë°ì´íŠ¸"""
        report.correct_count = sum(1 for i in report.items if i.is_correct is True)
        report.incorrect_count = sum(1 for i in report.items if i.is_correct is False)
        report.pending_count = sum(1 for i in report.items if i.is_correct is None)
        
        reviewed = report.correct_count + report.incorrect_count
        if reviewed > 0:
            report.accuracy_rate = report.correct_count / reviewed
        
        return report
    
    def generate_summary(self, report: ReviewReport) -> str:
        """ê²€í†  ìš”ì•½ ìƒì„±"""
        lines = [
            "=" * 50,
            f"ğŸ“Š AMAA Review Report",
            f"Session: {report.session_id}",
            f"Reviewed: {report.reviewed_at}",
            "=" * 50,
            "",
            "ğŸ“ˆ Statistics:",
            f"  Total Items: {report.total_items}",
            f"  Correct: {report.correct_count} âœ…",
            f"  Incorrect: {report.incorrect_count} âŒ",
            f"  Pending: {report.pending_count} â³",
            f"  Accuracy: {report.accuracy_rate:.1%}",
            "",
        ]
        
        # ì˜ëª»ëœ í•­ëª© ìƒì„¸
        incorrect_items = [i for i in report.items if i.is_correct is False]
        if incorrect_items:
            lines.append("âŒ Incorrect Items:")
            for item in incorrect_items[:10]:
                lines.append(f"  - {Path(item.file_path).name}")
                lines.append(f"    From: {item.original_path}")
                if item.user_feedback:
                    lines.append(f"    Feedback: {item.user_feedback}")
            lines.append("")
        
        # ì¶”ì²œì‚¬í•­
        if report.recommendations:
            lines.append("ğŸ’¡ Recommendations:")
            for rec in report.recommendations:
                lines.append(f"  - {rec}")
        
        return '\n'.join(lines)
    
    def analyze_patterns(self, report: ReviewReport) -> List[str]:
        """
        í”¼ë“œë°± íŒ¨í„´ ë¶„ì„ ë° ê°œì„  ì œì•ˆ ìƒì„±
        
        Args:
            report: ê²€í†  ë³´ê³ ì„œ
            
        Returns:
            List[str]: ê°œì„  ì œì•ˆ ëª©ë¡
        """
        recommendations = []
        
        # ì •í™•ë„ ê¸°ë°˜ ì œì•ˆ
        if report.accuracy_rate < 0.8:
            recommendations.append(
                "Consider reviewing the category rules - accuracy is below 80%"
            )
        
        # ì˜ëª»ëœ í•­ëª© ë¶„ì„
        incorrect_items = [i for i in report.items if i.is_correct is False]
        
        if incorrect_items:
            # í”¼ë“œë°±ì—ì„œ ê³µí†µ íŒ¨í„´ ì°¾ê¸°
            feedbacks = [i.user_feedback for i in incorrect_items if i.user_feedback]
            
            # í´ë” ê´€ë ¨ í”¼ë“œë°±
            folder_issues = [f for f in feedbacks if 'folder' in f.lower()]
            if len(folder_issues) > 2:
                recommendations.append(
                    f"Folder classification needs improvement - {len(folder_issues)} issues reported"
                )
            
            # ì¹´í…Œê³ ë¦¬ ê´€ë ¨ í”¼ë“œë°±
            category_issues = [f for f in feedbacks if 'category' in f.lower()]
            if len(category_issues) > 2:
                recommendations.append(
                    f"Category detection needs tuning - {len(category_issues)} issues reported"
                )
        
        # LLMìœ¼ë¡œ ì¶”ê°€ ë¶„ì„
        if incorrect_items and self.ollama.is_available():
            llm_suggestions = self._get_llm_suggestions(incorrect_items)
            recommendations.extend(llm_suggestions)
        
        report.recommendations = recommendations
        return recommendations
    
    def _get_llm_suggestions(self, incorrect_items: List[ReviewItem]) -> List[str]:
        """LLMì„ í†µí•œ ê°œì„  ì œì•ˆ"""
        try:
            # í”¼ë“œë°± ìš”ì•½
            feedbacks = [
                f"- {Path(i.file_path).name}: {i.user_feedback}"
                for i in incorrect_items[:10]
                if i.user_feedback
            ]
            
            if not feedbacks:
                return []
            
            prompt = f"""ë‹¤ìŒì€ íŒŒì¼ ì¡°ì§í™” ì‹œìŠ¤í…œì—ì„œ ì˜ëª» ë¶„ë¥˜ëœ íŒŒì¼ë“¤ì˜ í”¼ë“œë°±ì…ë‹ˆë‹¤:

{chr(10).join(feedbacks)}

ì´ í”¼ë“œë°±ì„ ë¶„ì„í•˜ì—¬ ì‹œìŠ¤í…œ ê°œì„ ì„ ìœ„í•œ êµ¬ì²´ì ì¸ ì œì•ˆ 3ê°€ì§€ë¥¼ ì œì‹œí•´ì£¼ì„¸ìš”.
ê° ì œì•ˆì€ í•œ ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”."""
            
            response = self.ollama.generate(prompt)
            
            # ì‘ë‹µì—ì„œ ì œì•ˆ ì¶”ì¶œ
            suggestions = []
            for line in response.split('\n'):
                line = line.strip()
                if line and (line[0].isdigit() or line.startswith('-')):
                    # ë²ˆí˜¸ë‚˜ ëŒ€ì‹œ ì œê±°
                    suggestion = line.lstrip('0123456789.-) ')
                    if suggestion:
                        suggestions.append(suggestion)
            
            return suggestions[:3]
            
        except Exception:
            return []
    
    def get_feedback_history(self) -> List[Dict]:
        """í”¼ë“œë°± ì´ë ¥ ì¡°íšŒ"""
        return [item.to_dict() for item in self._feedback_history]
    
    def export_feedback(self, output_path: str) -> None:
        """í”¼ë“œë°± ë‚´ë³´ë‚´ê¸°"""
        import json
        
        data = {
            'exported_at': datetime.now().isoformat(),
            'total_feedback': len(self._feedback_history),
            'feedback': [item.to_dict() for item in self._feedback_history]
        }
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
    
    def learn_from_feedback(self) -> Dict[str, Any]:
        """
        í”¼ë“œë°±ìœ¼ë¡œë¶€í„° í•™ìŠµ (ê·œì¹™ ê°œì„  ì œì•ˆ)
        
        Returns:
            Dict: í•™ìŠµ ê²°ê³¼ ë° ì œì•ˆëœ ê·œì¹™ ë³€ê²½
        """
        if not self._feedback_history:
            return {'status': 'no_feedback', 'suggestions': []}
        
        # ì •ë‹µ/ì˜¤ë‹µ ë¶„ë¥˜
        correct = [i for i in self._feedback_history if i.is_correct]
        incorrect = [i for i in self._feedback_history if not i.is_correct]
        
        learning_result = {
            'status': 'analyzed',
            'total_samples': len(self._feedback_history),
            'correct_count': len(correct),
            'incorrect_count': len(incorrect),
            'accuracy': len(correct) / len(self._feedback_history) if self._feedback_history else 0,
            'suggestions': [],
            'rule_changes': []
        }
        
        # ì˜¤ë‹µ íŒ¨í„´ ë¶„ì„
        if incorrect:
            # íŒŒì¼ í™•ì¥ìë³„ ì˜¤ë¥˜ í†µê³„
            ext_errors = {}
            for item in incorrect:
                ext = Path(item.file_path).suffix.lower()
                ext_errors[ext] = ext_errors.get(ext, 0) + 1
            
            # ìì£¼ í‹€ë¦¬ëŠ” í™•ì¥ì
            for ext, count in sorted(ext_errors.items(), key=lambda x: -x[1])[:3]:
                learning_result['suggestions'].append(
                    f"Review classification rules for '{ext}' files ({count} errors)"
                )
                learning_result['rule_changes'].append({
                    'type': 'extension_review',
                    'extension': ext,
                    'error_count': count
                })
        
        return learning_result


if __name__ == "__main__":
    print("ğŸ” AMAA Reviewer Agent Test")
    print("=" * 50)
    
    reviewer = ReviewerAgent()
    
    # í…ŒìŠ¤íŠ¸ ì„¸ì…˜ ë°ì´í„°
    test_session = {
        'session_id': 'test_001',
        'changes': [
            {'source_path': '/test/file1.pdf', 'destination_path': '/Documents/file1.pdf', 'action': 'move', 'executed': True},
            {'source_path': '/test/image.jpg', 'destination_path': '/Images/image.jpg', 'action': 'move', 'executed': True},
            {'source_path': '/test/code.py', 'destination_path': '/Documents/code.py', 'action': 'move', 'executed': True},
        ]
    }
    
    # ê²€í†  ë³´ê³ ì„œ ìƒì„±
    report = reviewer.create_review(test_session)
    
    # í”¼ë“œë°± ì‹œë®¬ë ˆì´ì…˜
    reviewer.mark_correct(report.items[0])
    reviewer.mark_correct(report.items[1])
    reviewer.mark_incorrect(
        report.items[2], 
        "Python file should be in Code folder, not Documents",
        "/Code/code.py"
    )
    
    # í†µê³„ ì—…ë°ì´íŠ¸
    report = reviewer.update_report_stats(report)
    
    # íŒ¨í„´ ë¶„ì„
    reviewer.analyze_patterns(report)
    
    # ìš”ì•½ ì¶œë ¥
    print(reviewer.generate_summary(report))
