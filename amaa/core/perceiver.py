"""
AMAA v0.4 - Perceiver (Multimodal Data Extractor)
ë©€í‹°ëª¨ë‹¬ ë°ì´í„° ì¶”ì¶œ ë° Ollama ì—°ë™ ëª¨ë“ˆ

Step 2: ë©€í‹°ëª¨ë‹¬ ë°ì´í„° ì¶”ì¶œ ë° Ollama ì—°ë™
- PyMuPDFë¡œ ë¬¸ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
- Pillow + Ollama(LLaVA)ë¡œ ì´ë¯¸ì§€ ì‹œë§¨í‹± ìº¡ì…˜ ìƒì„±
- ê³„ì¸µì  ì¶”ë¡ ìœ¼ë¡œ ìµœì  ê²½ë¡œ ê²°ì •
"""

import base64
import json
import re
from pathlib import Path
from typing import Optional, Dict, List, Any, Tuple
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
import mimetypes
import httpx


class FileType(Enum):
    """íŒŒì¼ íƒ€ì… ì—´ê±°í˜•"""
    DOCUMENT = "document"
    IMAGE = "image"
    VIDEO = "video"
    AUDIO = "audio"
    CODE = "code"
    DATA = "data"
    ARCHIVE = "archive"
    UNKNOWN = "unknown"


@dataclass
class PerceptionResult:
    """ì¸ì‹ ê²°ê³¼ ë°ì´í„° í´ë˜ìŠ¤"""
    file_path: str
    file_type: FileType
    extracted_text: Optional[str] = None
    caption: Optional[str] = None
    keywords: List[str] = field(default_factory=list)
    entities: List[str] = field(default_factory=list)
    language: Optional[str] = None
    suggested_category: Optional[str] = None
    suggested_path: Optional[str] = None
    confidence: float = 0.0
    metadata: Dict[str, Any] = field(default_factory=dict)
    processing_time: float = 0.0
    error: Optional[str] = None
    
    def to_dict(self) -> dict:
        return {
            'file_path': self.file_path,
            'file_type': self.file_type.value,
            'extracted_text': self.extracted_text[:500] if self.extracted_text else None,
            'caption': self.caption,
            'keywords': self.keywords,
            'entities': self.entities,
            'language': self.language,
            'suggested_category': self.suggested_category,
            'suggested_path': self.suggested_path,
            'confidence': self.confidence,
            'metadata': self.metadata,
            'processing_time': self.processing_time,
            'error': self.error,
        }


class OllamaClient:
    """
    Ollama API í´ë¼ì´ì–¸íŠ¸
    
    ë¡œì»¬ LLMê³¼ í†µì‹ í•˜ì—¬ í…ìŠ¤íŠ¸/ì´ë¯¸ì§€ ë¶„ì„ ìˆ˜í–‰
    """
    
    def __init__(self, base_url: str = "http://localhost:11434",
                 model: str = "llama3.2",
                 vision_model: str = "llava",
                 timeout: int = 60):
        self.base_url = base_url.rstrip('/')
        self.model = model
        self.vision_model = vision_model
        self.timeout = timeout
        self._client = httpx.Client(timeout=timeout)
    
    def is_available(self) -> bool:
        """Ollama ì„œë²„ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
        try:
            response = self._client.get(f"{self.base_url}/api/tags")
            return response.status_code == 200
        except Exception:
            return False
    
    def list_models(self) -> List[str]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡"""
        try:
            response = self._client.get(f"{self.base_url}/api/tags")
            if response.status_code == 200:
                data = response.json()
                return [m['name'] for m in data.get('models', [])]
        except Exception:
            pass
        return []
    
    def generate(self, prompt: str, model: Optional[str] = None,
                 system: Optional[str] = None,
                 stream: bool = False) -> str:
        """
        í…ìŠ¤íŠ¸ ìƒì„±
        
        Args:
            prompt: ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸
            model: ì‚¬ìš©í•  ëª¨ë¸ (ê¸°ë³¸ê°’: self.model)
            system: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
            stream: ìŠ¤íŠ¸ë¦¬ë° ì—¬ë¶€
            
        Returns:
            str: ìƒì„±ëœ í…ìŠ¤íŠ¸
        """
        payload = {
            "model": model or self.model,
            "prompt": prompt,
            "stream": stream,
        }
        
        if system:
            payload["system"] = system
        
        try:
            response = self._client.post(
                f"{self.base_url}/api/generate",
                json=payload
            )
            
            if response.status_code == 200:
                data = response.json()
                return data.get('response', '')
            else:
                return f"Error: {response.status_code}"
        except Exception as e:
            return f"Error: {str(e)}"
    
    def generate_with_image(self, prompt: str, image_path: str,
                           model: Optional[str] = None) -> str:
        """
        ì´ë¯¸ì§€ì™€ í•¨ê»˜ í…ìŠ¤íŠ¸ ìƒì„± (LLaVA ë“± ë¹„ì „ ëª¨ë¸ìš©)
        
        Args:
            prompt: í”„ë¡¬í”„íŠ¸
            image_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
            model: ë¹„ì „ ëª¨ë¸ (ê¸°ë³¸ê°’: self.vision_model)
            
        Returns:
            str: ìƒì„±ëœ í…ìŠ¤íŠ¸ (ìº¡ì…˜ ë“±)
        """
        # ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©
        path = Path(image_path)
        if not path.exists():
            return f"Error: Image not found: {image_path}"
        
        with open(path, 'rb') as f:
            image_data = base64.b64encode(f.read()).decode('utf-8')
        
        payload = {
            "model": model or self.vision_model,
            "prompt": prompt,
            "images": [image_data],
            "stream": False,
        }
        
        try:
            response = self._client.post(
                f"{self.base_url}/api/generate",
                json=payload
            )
            
            if response.status_code == 200:
                data = response.json()
                return data.get('response', '')
            else:
                return f"Error: {response.status_code}"
        except Exception as e:
            return f"Error: {str(e)}"
    
    def chat(self, messages: List[Dict[str, str]], 
             model: Optional[str] = None) -> str:
        """
        ì±„íŒ… í˜•ì‹ì˜ ëŒ€í™”
        
        Args:
            messages: [{"role": "user/assistant/system", "content": "..."}]
            model: ì‚¬ìš©í•  ëª¨ë¸
            
        Returns:
            str: ì‘ë‹µ ë©”ì‹œì§€
        """
        payload = {
            "model": model or self.model,
            "messages": messages,
            "stream": False,
        }
        
        try:
            response = self._client.post(
                f"{self.base_url}/api/chat",
                json=payload
            )
            
            if response.status_code == 200:
                data = response.json()
                return data.get('message', {}).get('content', '')
            else:
                return f"Error: {response.status_code}"
        except Exception as e:
            return f"Error: {str(e)}"
    
    def close(self):
        """í´ë¼ì´ì–¸íŠ¸ ì¢…ë£Œ"""
        self._client.close()


class Perceiver:
    """
    ë©€í‹°ëª¨ë‹¬ ë°ì´í„° ì¸ì‹ ì—”ì§„
    
    ë‹¤ì–‘í•œ íŒŒì¼ íƒ€ì…ì—ì„œ ì˜ë¯¸ ìˆëŠ” ì •ë³´ë¥¼ ì¶”ì¶œí•˜ê³ ,
    Ollamaë¥¼ í†µí•´ ì§€ëŠ¥í˜• ë¶„ë¥˜ë¥¼ ìˆ˜í–‰
    
    Usage:
        perceiver = Perceiver(config, directory_tree)
        result = perceiver.perceive("/path/to/file.pdf")
        print(result.suggested_path)
    """
    
    # íŒŒì¼ í™•ì¥ì â†’ FileType ë§¤í•‘
    EXTENSION_MAP = {
        # Documents
        '.pdf': FileType.DOCUMENT,
        '.docx': FileType.DOCUMENT,
        '.doc': FileType.DOCUMENT,
        '.txt': FileType.DOCUMENT,
        '.md': FileType.DOCUMENT,
        '.xlsx': FileType.DOCUMENT,
        '.xls': FileType.DOCUMENT,
        '.pptx': FileType.DOCUMENT,
        '.rtf': FileType.DOCUMENT,
        
        # Images
        '.jpg': FileType.IMAGE,
        '.jpeg': FileType.IMAGE,
        '.png': FileType.IMAGE,
        '.gif': FileType.IMAGE,
        '.webp': FileType.IMAGE,
        '.heic': FileType.IMAGE,
        '.bmp': FileType.IMAGE,
        '.svg': FileType.IMAGE,
        
        # Videos
        '.mp4': FileType.VIDEO,
        '.mov': FileType.VIDEO,
        '.avi': FileType.VIDEO,
        '.mkv': FileType.VIDEO,
        '.webm': FileType.VIDEO,
        
        # Audio
        '.mp3': FileType.AUDIO,
        '.wav': FileType.AUDIO,
        '.flac': FileType.AUDIO,
        '.m4a': FileType.AUDIO,
        '.aac': FileType.AUDIO,
        
        # Code
        '.py': FileType.CODE,
        '.js': FileType.CODE,
        '.ts': FileType.CODE,
        '.java': FileType.CODE,
        '.cpp': FileType.CODE,
        '.c': FileType.CODE,
        '.go': FileType.CODE,
        '.rs': FileType.CODE,
        '.html': FileType.CODE,
        '.css': FileType.CODE,
        
        # Data
        '.json': FileType.DATA,
        '.xml': FileType.DATA,
        '.csv': FileType.DATA,
        '.yaml': FileType.DATA,
        '.yml': FileType.DATA,
        '.sql': FileType.DATA,
        
        # Archives
        '.zip': FileType.ARCHIVE,
        '.tar': FileType.ARCHIVE,
        '.gz': FileType.ARCHIVE,
        '.7z': FileType.ARCHIVE,
        '.rar': FileType.ARCHIVE,
    }
    
    def __init__(self, config=None, directory_context: Optional[str] = None):
        """
        Args:
            config: AMAA Config ê°ì²´
            directory_context: í˜„ì¬ ë””ë ‰í† ë¦¬ êµ¬ì¡° ì»¨í…ìŠ¤íŠ¸ (LLMìš©)
        """
        self.config = config
        self.directory_context = directory_context
        
        # Ollama í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        if config:
            self.ollama = OllamaClient(
                base_url=config.ollama.base_url,
                model=config.ollama.model,
                vision_model=config.ollama.vision_model,
                timeout=config.ollama.timeout
            )
        else:
            self.ollama = OllamaClient()
        
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        self.system_prompt = self._build_system_prompt()
    
    def _build_system_prompt(self) -> str:
        """LLM ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        return """ë‹¹ì‹ ì€ íŒŒì¼ ë¶„ë¥˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
íŒŒì¼ì˜ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ê°€ì¥ ì í•©í•œ ì €ì¥ ê²½ë¡œë¥¼ ê²°ì •í•©ë‹ˆë‹¤.

ê·œì¹™:
1. ISO 8601 ë‚ ì§œ í˜•ì‹(YYYY-MM-DD)ì„ íŒŒì¼ëª… ì ‘ë‘ì–´ë¡œ ì‚¬ìš©
2. ì¹´í…Œê³ ë¦¬(documents, images, projects ë“±)ì— ë”°ë¼ í´ë” êµ¬ë¶„
3. ê¸°ì¡´ ë””ë ‰í† ë¦¬ êµ¬ì¡°ë¥¼ ì¡´ì¤‘í•˜ì—¬ ì¼ê´€ì„± ìœ ì§€
4. í”„ë¡œì íŠ¸ ê´€ë ¨ íŒŒì¼ì€ í”„ë¡œì íŠ¸ í´ë”ì— ê·¸ë£¹í™”

ì‘ë‹µ í˜•ì‹:
- suggested_path: ì œì•ˆí•˜ëŠ” ì ˆëŒ€ ê²½ë¡œ
- category: íŒŒì¼ ì¹´í…Œê³ ë¦¬
- confidence: ì‹ ë¢°ë„ (0.0 ~ 1.0)
- reasoning: ê²°ì • ì´ìœ  (ê°„ë‹¨íˆ)"""
    
    def perceive(self, file_path: str) -> PerceptionResult:
        """
        íŒŒì¼ ì¸ì‹ ë° ë¶„ì„ ìˆ˜í–‰
        
        Args:
            file_path: ë¶„ì„í•  íŒŒì¼ ê²½ë¡œ
            
        Returns:
            PerceptionResult: ì¸ì‹ ê²°ê³¼
        """
        start_time = datetime.now()
        path = Path(file_path).expanduser().resolve()
        
        if not path.exists():
            return PerceptionResult(
                file_path=str(path),
                file_type=FileType.UNKNOWN,
                error=f"File not found: {file_path}"
            )
        
        # íŒŒì¼ íƒ€ì… ê²°ì •
        file_type = self._detect_file_type(path)
        
        # ê¸°ë³¸ ê²°ê³¼ ì´ˆê¸°í™”
        result = PerceptionResult(
            file_path=str(path),
            file_type=file_type,
            metadata=self._extract_metadata(path)
        )
        
        try:
            # íŒŒì¼ íƒ€ì…ë³„ ì²˜ë¦¬
            if file_type == FileType.DOCUMENT:
                result = self._perceive_document(path, result)
            elif file_type == FileType.IMAGE:
                result = self._perceive_image(path, result)
            elif file_type == FileType.VIDEO:
                result = self._perceive_video(path, result)
            elif file_type == FileType.CODE:
                result = self._perceive_code(path, result)
            elif file_type == FileType.DATA:
                result = self._perceive_data(path, result)
            else:
                result = self._perceive_generic(path, result)
            
            # LLMì„ í†µí•œ ê²½ë¡œ ì œì•ˆ
            if self.ollama.is_available():
                result = self._suggest_path_with_llm(result)
            
        except Exception as e:
            result.error = str(e)
        
        result.processing_time = (datetime.now() - start_time).total_seconds()
        return result
    
    def _detect_file_type(self, path: Path) -> FileType:
        """íŒŒì¼ íƒ€ì… ê°ì§€"""
        ext = path.suffix.lower()
        
        if ext in self.EXTENSION_MAP:
            return self.EXTENSION_MAP[ext]
        
        # MIME íƒ€ì…ìœ¼ë¡œ ì¶”ì¸¡
        mime_type, _ = mimetypes.guess_type(str(path))
        if mime_type:
            if mime_type.startswith('image/'):
                return FileType.IMAGE
            elif mime_type.startswith('video/'):
                return FileType.VIDEO
            elif mime_type.startswith('audio/'):
                return FileType.AUDIO
            elif mime_type.startswith('text/'):
                return FileType.DOCUMENT
        
        return FileType.UNKNOWN
    
    def _extract_metadata(self, path: Path) -> dict:
        """ê¸°ë³¸ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"""
        stat = path.stat()
        return {
            'name': path.name,
            'extension': path.suffix.lower(),
            'size': stat.st_size,
            'created': datetime.fromtimestamp(stat.st_ctime).isoformat(),
            'modified': datetime.fromtimestamp(stat.st_mtime).isoformat(),
            'mime_type': mimetypes.guess_type(str(path))[0],
        }
    
    def _perceive_document(self, path: Path, result: PerceptionResult) -> PerceptionResult:
        """ë¬¸ì„œ íŒŒì¼ ë¶„ì„"""
        ext = path.suffix.lower()
        
        if ext == '.pdf':
            result.extracted_text = self._extract_pdf_text(path)
        elif ext == '.txt':
            result.extracted_text = self._extract_text_file(path)
        elif ext == '.md':
            result.extracted_text = self._extract_text_file(path)
        elif ext in ['.docx', '.doc']:
            result.extracted_text = self._extract_docx_text(path)
        
        # í…ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œ/ì—”í‹°í‹° ì¶”ì¶œ
        if result.extracted_text:
            result.keywords = self._extract_keywords(result.extracted_text)
            result.entities = self._extract_entities(result.extracted_text)
            result.language = self._detect_language(result.extracted_text)
        
        return result
    
    def _perceive_image(self, path: Path, result: PerceptionResult) -> PerceptionResult:
        """ì´ë¯¸ì§€ íŒŒì¼ ë¶„ì„ (LLaVA ì‚¬ìš©)"""
        
        # EXIF ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
        result.metadata.update(self._extract_image_metadata(path))
        
        # LLaVAë¡œ ì´ë¯¸ì§€ ìº¡ì…˜ ìƒì„±
        if self.ollama.is_available():
            prompt = """ì´ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”:
1. ì£¼ìš” ë‚´ìš© ì„¤ëª… (í•œ ë¬¸ì¥)
2. í‚¤ì›Œë“œ 3-5ê°œ
3. ì í•©í•œ ë¶„ë¥˜ ì¹´í…Œê³ ë¦¬ (ì‚¬ì§„, ìŠ¤í¬ë¦°ìƒ·, ë¬¸ì„œìŠ¤ìº”, ê·¸ë˜í”½, ê¸°íƒ€)

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:
{"caption": "...", "keywords": [...], "category": "..."}"""
            
            response = self.ollama.generate_with_image(prompt, str(path))
            
            try:
                # JSON íŒŒì‹± ì‹œë„
                data = json.loads(response)
                result.caption = data.get('caption', '')
                result.keywords = data.get('keywords', [])
                result.suggested_category = data.get('category', '')
            except json.JSONDecodeError:
                # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ í…ìŠ¤íŠ¸ë¡œ ì €ì¥
                result.caption = response
        
        return result
    
    def _perceive_video(self, path: Path, result: PerceptionResult) -> PerceptionResult:
        """ë¹„ë””ì˜¤ íŒŒì¼ ë¶„ì„"""
        
        # ì¸ë„¤ì¼ ì¶”ì¶œ í›„ ì´ë¯¸ì§€ ë¶„ì„
        thumbnail = self._extract_video_thumbnail(path)
        
        if thumbnail and self.ollama.is_available():
            prompt = "ì´ ë¹„ë””ì˜¤ í”„ë ˆì„ì„ ë¶„ì„í•˜ì—¬ ë¹„ë””ì˜¤ ë‚´ìš©ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”."
            result.caption = self.ollama.generate_with_image(prompt, thumbnail)
            
            # ì„ì‹œ ì¸ë„¤ì¼ ì‚­ì œ
            try:
                Path(thumbnail).unlink()
            except:
                pass
        
        # ë¹„ë””ì˜¤ ë©”íƒ€ë°ì´í„°
        result.metadata.update(self._extract_video_metadata(path))
        
        return result
    
    def _perceive_code(self, path: Path, result: PerceptionResult) -> PerceptionResult:
        """ì½”ë“œ íŒŒì¼ ë¶„ì„"""
        
        result.extracted_text = self._extract_text_file(path)
        
        if result.extracted_text:
            # ì–¸ì–´ ê°ì§€
            result.language = path.suffix.replace('.', '')
            
            # ì½”ë“œì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ (í´ë˜ìŠ¤ëª…, í•¨ìˆ˜ëª… ë“±)
            result.keywords = self._extract_code_symbols(result.extracted_text, result.language)
            
            # í”„ë¡œì íŠ¸ ê´€ë ¨ ì •ë³´ ì¶”ì¶œ
            result.entities = self._extract_imports(result.extracted_text, result.language)
        
        return result
    
    def _perceive_data(self, path: Path, result: PerceptionResult) -> PerceptionResult:
        """ë°ì´í„° íŒŒì¼ ë¶„ì„"""
        ext = path.suffix.lower()
        
        if ext == '.json':
            result.metadata.update(self._analyze_json(path))
        elif ext == '.csv':
            result.metadata.update(self._analyze_csv(path))
        elif ext in ['.yaml', '.yml']:
            result.extracted_text = self._extract_text_file(path)
        
        return result
    
    def _perceive_generic(self, path: Path, result: PerceptionResult) -> PerceptionResult:
        """ì¼ë°˜ íŒŒì¼ ë¶„ì„"""
        # íŒŒì¼ëª…ì—ì„œ ì •ë³´ ì¶”ì¶œ
        result.keywords = self._extract_from_filename(path.stem)
        return result
    
    def _suggest_path_with_llm(self, result: PerceptionResult) -> PerceptionResult:
        """
        LLMì„ í†µí•œ ê³„ì¸µì  ì¶”ë¡ ìœ¼ë¡œ ìµœì  ê²½ë¡œ ì œì•ˆ
        
        ë””ë ‰í† ë¦¬ ì»¨í…ìŠ¤íŠ¸ì™€ íŒŒì¼ ì •ë³´ë¥¼ í•¨ê»˜ ì „ë‹¬í•˜ì—¬
        ê¸°ì¡´ ë¶„ë¥˜ ì²´ê³„ì— ë§ëŠ” ê²½ë¡œë¥¼ ì œì•ˆë°›ìŒ
        """
        
        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        file_info = f"""
íŒŒì¼ ì •ë³´:
- ì´ë¦„: {result.metadata.get('name', '')}
- íƒ€ì…: {result.file_type.value}
- í¬ê¸°: {result.metadata.get('size', 0)} bytes
- ìˆ˜ì •ì¼: {result.metadata.get('modified', '')}
"""
        
        if result.extracted_text:
            file_info += f"- ë‚´ìš© ìš”ì•½: {result.extracted_text[:500]}...\n"
        
        if result.caption:
            file_info += f"- ì´ë¯¸ì§€ ìº¡ì…˜: {result.caption}\n"
        
        if result.keywords:
            file_info += f"- í‚¤ì›Œë“œ: {', '.join(result.keywords)}\n"
        
        # ë””ë ‰í† ë¦¬ ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
        context = ""
        if self.directory_context:
            context = f"""
í˜„ì¬ ë””ë ‰í† ë¦¬ êµ¬ì¡°:
{self.directory_context}
"""
        
        prompt = f"""{file_info}
{context}

ì´ íŒŒì¼ì— ê°€ì¥ ì í•©í•œ ì €ì¥ ê²½ë¡œë¥¼ JSONìœ¼ë¡œ ì œì•ˆí•´ì£¼ì„¸ìš”:
{{"suggested_path": "/path/to/store", "category": "...", "confidence": 0.0-1.0, "reasoning": "..."}}"""
        
        response = self.ollama.generate(prompt, system=self.system_prompt)
        
        try:
            # JSON ì¶”ì¶œ ì‹œë„
            json_match = re.search(r'\{[^{}]+\}', response, re.DOTALL)
            if json_match:
                data = json.loads(json_match.group())
                result.suggested_path = data.get('suggested_path')
                result.suggested_category = data.get('category')
                result.confidence = float(data.get('confidence', 0.5))
        except (json.JSONDecodeError, ValueError):
            # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ìœ ì§€
            pass
        
        return result
    
    # ============================================================
    # í…ìŠ¤íŠ¸ ì¶”ì¶œ ë©”ì„œë“œë“¤
    # ============================================================
    
    def _extract_pdf_text(self, path: Path) -> str:
        """PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (PyMuPDF)"""
        try:
            import fitz  # PyMuPDF
            
            text_parts = []
            with fitz.open(str(path)) as doc:
                for page in doc:
                    text_parts.append(page.get_text())
            
            return '\n'.join(text_parts)
        except ImportError:
            return "[PyMuPDF not installed]"
        except Exception as e:
            return f"[Error extracting PDF: {e}]"
    
    def _extract_text_file(self, path: Path, max_size: int = 1_000_000) -> str:
        """í…ìŠ¤íŠ¸ íŒŒì¼ ì½ê¸°"""
        try:
            # ì¸ì½”ë”© ê°ì§€
            import chardet
            
            with open(path, 'rb') as f:
                raw = f.read(min(max_size, path.stat().st_size))
            
            detected = chardet.detect(raw)
            encoding = detected.get('encoding', 'utf-8')
            
            return raw.decode(encoding, errors='replace')
        except ImportError:
            # chardet ì—†ìœ¼ë©´ utf-8ë¡œ ì‹œë„
            try:
                return path.read_text(encoding='utf-8')
            except:
                return path.read_text(encoding='latin-1', errors='replace')
        except Exception as e:
            return f"[Error reading file: {e}]"
    
    def _extract_docx_text(self, path: Path) -> str:
        """DOCXì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        try:
            from zipfile import ZipFile
            from xml.etree import ElementTree
            
            with ZipFile(str(path)) as docx:
                content = docx.read('word/document.xml')
            
            tree = ElementTree.fromstring(content)
            
            # Word XML ë„¤ì„ìŠ¤í˜ì´ìŠ¤
            ns = {'w': 'http://schemas.openxmlformats.org/wordprocessingml/2006/main'}
            
            texts = []
            for para in tree.findall('.//w:p', ns):
                para_text = ''.join(
                    node.text for node in para.findall('.//w:t', ns) if node.text
                )
                texts.append(para_text)
            
            return '\n'.join(texts)
        except Exception as e:
            return f"[Error extracting DOCX: {e}]"
    
    # ============================================================
    # ì´ë¯¸ì§€/ë¹„ë””ì˜¤ ì²˜ë¦¬ ë©”ì„œë“œë“¤
    # ============================================================
    
    def _extract_image_metadata(self, path: Path) -> dict:
        """ì´ë¯¸ì§€ EXIF ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"""
        try:
            from PIL import Image
            from PIL.ExifTags import TAGS
            
            with Image.open(str(path)) as img:
                metadata = {
                    'width': img.width,
                    'height': img.height,
                    'format': img.format,
                    'mode': img.mode,
                }
                
                # EXIF ë°ì´í„°
                exif = img._getexif()
                if exif:
                    for tag_id, value in exif.items():
                        tag = TAGS.get(tag_id, tag_id)
                        if isinstance(value, (str, int, float)):
                            metadata[f'exif_{tag}'] = value
                
                return metadata
        except ImportError:
            return {'error': 'Pillow not installed'}
        except Exception as e:
            return {'error': str(e)}
    
    def _extract_video_thumbnail(self, path: Path) -> Optional[str]:
        """ë¹„ë””ì˜¤ì—ì„œ ì¸ë„¤ì¼ ì¶”ì¶œ"""
        try:
            import cv2
            
            cap = cv2.VideoCapture(str(path))
            
            # ì²« í”„ë ˆì„ ë˜ëŠ” ì¤‘ê°„ í”„ë ˆì„
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            cap.set(cv2.CAP_PROP_POS_FRAMES, min(30, total_frames // 2))
            
            ret, frame = cap.read()
            cap.release()
            
            if ret:
                thumb_path = path.parent / f".thumb_{path.stem}.jpg"
                cv2.imwrite(str(thumb_path), frame)
                return str(thumb_path)
        except ImportError:
            pass
        except Exception:
            pass
        
        return None
    
    def _extract_video_metadata(self, path: Path) -> dict:
        """ë¹„ë””ì˜¤ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"""
        try:
            import cv2
            
            cap = cv2.VideoCapture(str(path))
            
            metadata = {
                'width': int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),
                'height': int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)),
                'fps': cap.get(cv2.CAP_PROP_FPS),
                'frame_count': int(cap.get(cv2.CAP_PROP_FRAME_COUNT)),
                'duration': cap.get(cv2.CAP_PROP_FRAME_COUNT) / max(cap.get(cv2.CAP_PROP_FPS), 1),
            }
            
            cap.release()
            return metadata
        except ImportError:
            return {'error': 'OpenCV not installed'}
        except Exception as e:
            return {'error': str(e)}
    
    # ============================================================
    # í…ìŠ¤íŠ¸ ë¶„ì„ ë©”ì„œë“œë“¤
    # ============================================================
    
    def _extract_keywords(self, text: str, top_n: int = 10) -> List[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ (ê°„ë‹¨í•œ TF ê¸°ë°˜)"""
        import re
        from collections import Counter
        
        # ë‹¨ì–´ ì¶”ì¶œ (í•œê¸€, ì˜ë¬¸ ëª¨ë‘)
        words = re.findall(r'[\wê°€-í£]{2,}', text.lower())
        
        # ë¶ˆìš©ì–´ ì œê±°
        stopwords = {'the', 'a', 'an', 'is', 'are', 'was', 'were', 'be', 'been',
                    'ì´', 'ê·¸', 'ì €', 'ê²ƒ', 'ìˆ˜', 'ë“±', 'ë°', 'ì˜', 'ë¥¼', 'ì„', 'ì—'}
        words = [w for w in words if w not in stopwords and len(w) > 2]
        
        # ë¹ˆë„ìˆ˜ ê¸°ë°˜ ìƒìœ„ í‚¤ì›Œë“œ
        counter = Counter(words)
        return [word for word, _ in counter.most_common(top_n)]
    
    def _extract_entities(self, text: str) -> List[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ ì—”í‹°í‹°(ê³ ìœ ëª…ì‚¬ ë“±) ì¶”ì¶œ"""
        import re
        
        entities = []
        
        # ì´ë©”ì¼
        emails = re.findall(r'[\w.-]+@[\w.-]+\.\w+', text)
        entities.extend(emails)
        
        # URL
        urls = re.findall(r'https?://[^\s]+', text)
        entities.extend(urls)
        
        # ë‚ ì§œ
        dates = re.findall(r'\d{4}[-/]\d{2}[-/]\d{2}', text)
        entities.extend(dates)
        
        # ëŒ€ë¬¸ìë¡œ ì‹œì‘í•˜ëŠ” ë‹¨ì–´ (ê³ ìœ ëª…ì‚¬ ì¶”ì •)
        proper_nouns = re.findall(r'\b[A-Z][a-z]+(?:\s+[A-Z][a-z]+)*\b', text)
        entities.extend(proper_nouns[:10])
        
        return list(set(entities))[:20]
    
    def _detect_language(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ì–¸ì–´ ê°ì§€ (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)"""
        # í•œê¸€ ë¹„ìœ¨ ì²´í¬
        korean_chars = len(re.findall(r'[ê°€-í£]', text))
        total_chars = len(text)
        
        if total_chars > 0 and korean_chars / total_chars > 0.3:
            return 'ko'
        
        # ì¼ë³¸ì–´ ì²´í¬
        japanese_chars = len(re.findall(r'[\u3040-\u30ff]', text))
        if total_chars > 0 and japanese_chars / total_chars > 0.1:
            return 'ja'
        
        # ì¤‘êµ­ì–´ ì²´í¬
        chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', text))
        if total_chars > 0 and chinese_chars / total_chars > 0.1:
            return 'zh'
        
        return 'en'
    
    def _extract_code_symbols(self, code: str, language: str) -> List[str]:
        """ì½”ë“œì—ì„œ ì‹¬ë³¼(í´ë˜ìŠ¤, í•¨ìˆ˜ëª… ë“±) ì¶”ì¶œ"""
        import re
        
        symbols = []
        
        if language in ['py', 'python']:
            # Python í´ë˜ìŠ¤/í•¨ìˆ˜
            classes = re.findall(r'class\s+(\w+)', code)
            functions = re.findall(r'def\s+(\w+)', code)
            symbols.extend(classes)
            symbols.extend(functions)
        
        elif language in ['js', 'ts', 'javascript', 'typescript']:
            # JS/TS í•¨ìˆ˜/í´ë˜ìŠ¤
            classes = re.findall(r'class\s+(\w+)', code)
            functions = re.findall(r'function\s+(\w+)', code)
            arrow_funcs = re.findall(r'const\s+(\w+)\s*=\s*(?:\([^)]*\)|[^=])\s*=>', code)
            symbols.extend(classes)
            symbols.extend(functions)
            symbols.extend(arrow_funcs)
        
        elif language in ['java', 'cpp', 'c', 'c++']:
            # Java/C++ í´ë˜ìŠ¤/ë©”ì„œë“œ
            classes = re.findall(r'class\s+(\w+)', code)
            symbols.extend(classes)
        
        return list(set(symbols))[:20]
    
    def _extract_imports(self, code: str, language: str) -> List[str]:
        """ì½”ë“œì—ì„œ import ë¬¸ ì¶”ì¶œ"""
        import re
        
        imports = []
        
        if language in ['py', 'python']:
            # Python imports
            imports.extend(re.findall(r'^import\s+(\w+)', code, re.MULTILINE))
            imports.extend(re.findall(r'^from\s+(\w+)', code, re.MULTILINE))
        
        elif language in ['js', 'ts', 'javascript', 'typescript']:
            # JS/TS imports
            imports.extend(re.findall(r"import\s+.*from\s+['\"]([^'\"]+)['\"]", code))
            imports.extend(re.findall(r"require\(['\"]([^'\"]+)['\"]\)", code))
        
        elif language == 'java':
            imports.extend(re.findall(r'^import\s+([\w.]+)', code, re.MULTILINE))
        
        return list(set(imports))
    
    def _extract_from_filename(self, filename: str) -> List[str]:
        """íŒŒì¼ëª…ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        import re
        
        # êµ¬ë¶„ìë¡œ ë¶„ë¦¬
        parts = re.split(r'[-_\s.]+', filename)
        
        # ë‚ ì§œ ì œê±°
        keywords = [p for p in parts if not re.match(r'^\d{4,8}$', p)]
        
        return [k for k in keywords if len(k) > 2]
    
    def _analyze_json(self, path: Path) -> dict:
        """JSON íŒŒì¼ ë¶„ì„"""
        try:
            with open(path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            return {
                'json_type': type(data).__name__,
                'json_keys': list(data.keys())[:10] if isinstance(data, dict) else None,
                'json_length': len(data) if isinstance(data, (list, dict)) else None,
            }
        except:
            return {}
    
    def _analyze_csv(self, path: Path) -> dict:
        """CSV íŒŒì¼ ë¶„ì„"""
        try:
            with open(path, 'r', encoding='utf-8') as f:
                first_lines = [f.readline() for _ in range(5)]
            
            # í—¤ë” ì¶”ì¶œ
            header = first_lines[0].strip().split(',') if first_lines else []
            
            return {
                'csv_columns': header[:10],
                'csv_preview_rows': len([l for l in first_lines if l.strip()]) - 1,
            }
        except:
            return {}
    
    def set_directory_context(self, context: str) -> None:
        """ë””ë ‰í† ë¦¬ ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸"""
        self.directory_context = context
    
    def batch_perceive(self, file_paths: List[str], 
                       progress_callback=None) -> List[PerceptionResult]:
        """ì—¬ëŸ¬ íŒŒì¼ ì¼ê´„ ë¶„ì„"""
        results = []
        total = len(file_paths)
        
        for i, path in enumerate(file_paths):
            result = self.perceive(path)
            results.append(result)
            
            if progress_callback:
                progress_callback(i + 1, total, path)
        
        return results


if __name__ == "__main__":
    import sys
    
    # Ollama ì—°ê²° í…ŒìŠ¤íŠ¸
    print("ğŸ” Testing Ollama connection...")
    ollama = OllamaClient()
    
    if ollama.is_available():
        print("âœ… Ollama is available")
        print(f"ğŸ“‹ Available models: {ollama.list_models()}")
    else:
        print("âŒ Ollama is not available")
        print("   Please start Ollama: ollama serve")
    
    # íŒŒì¼ ë¶„ì„ í…ŒìŠ¤íŠ¸
    if len(sys.argv) > 1:
        test_file = sys.argv[1]
        print(f"\nğŸ” Analyzing: {test_file}")
        
        perceiver = Perceiver()
        result = perceiver.perceive(test_file)
        
        print(f"\nğŸ“Š Results:")
        print(f"  File Type: {result.file_type.value}")
        print(f"  Keywords: {result.keywords}")
        print(f"  Suggested Category: {result.suggested_category}")
        print(f"  Suggested Path: {result.suggested_path}")
        print(f"  Confidence: {result.confidence}")
        print(f"  Processing Time: {result.processing_time:.2f}s")
