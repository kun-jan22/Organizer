"""
AMAA v0.4 - MapMaker (Directory Indexer)
ë””ë ‰í† ë¦¬ êµ¬ì¡° ìŠ¤ìº” ë° ë¶„ë¥˜ ì²´ê³„(Taxonomy) ì¶”ì¶œ ëª¨ë“ˆ

Step 1: í™˜ê²½ ì„¤ì • ë° ë””ë ‰í† ë¦¬ ì¸ë±ì„œ êµ¬í˜„
- pathlibì„ ì‚¬ìš©í•œ ì¬ê·€ì  ë””ë ‰í† ë¦¬ ìŠ¤ìº”
- JSON íŠ¸ë¦¬ êµ¬ì¡° ìƒì„±
- ì‚¬ìš©ìì˜ ê¸°ì¡´ ë¶„ë¥˜ ìŠµê´€(Taxonomy) ì¶”ì¶œ
"""

import json
import hashlib
import mimetypes
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional, Generator, Any, Set
from dataclasses import dataclass, field, asdict
from concurrent.futures import ThreadPoolExecutor, as_completed
import os
import stat


@dataclass
class FileInfo:
    """íŒŒì¼ ì •ë³´ ë°ì´í„° í´ë˜ìŠ¤"""
    path: str
    name: str
    extension: str
    size: int
    created: str
    modified: str
    category: Optional[str] = None
    mime_type: Optional[str] = None
    is_hidden: bool = False
    depth: int = 0
    checksum: Optional[str] = None
    
    def to_dict(self) -> dict:
        return asdict(self)


@dataclass
class DirectoryInfo:
    """ë””ë ‰í† ë¦¬ ì •ë³´ ë°ì´í„° í´ë˜ìŠ¤"""
    path: str
    name: str
    depth: int
    file_count: int = 0
    dir_count: int = 0
    total_size: int = 0
    children: List[Any] = field(default_factory=list)
    files: List[FileInfo] = field(default_factory=list)
    
    def to_dict(self) -> dict:
        result = {
            'path': self.path,
            'name': self.name,
            'depth': self.depth,
            'file_count': self.file_count,
            'dir_count': self.dir_count,
            'total_size': self.total_size,
            'children': [c.to_dict() if hasattr(c, 'to_dict') else c for c in self.children],
            'files': [f.to_dict() for f in self.files]
        }
        return result


@dataclass
class TaxonomyPattern:
    """ë¶„ë¥˜ ì²´ê³„ íŒ¨í„´"""
    pattern: str
    count: int
    examples: List[str]
    depth: int
    category_guess: Optional[str] = None


class MapMaker:
    """
    ë””ë ‰í† ë¦¬ ì¸ë±ì„œ - ë¡œì»¬ íŒŒì¼ ì‹œìŠ¤í…œì„ ìŠ¤ìº”í•˜ê³  JSON íŠ¸ë¦¬ ìƒì„±
    
    ì‚¬ìš©ìì˜ ê¸°ì¡´ ë¶„ë¥˜ ìŠµê´€(Taxonomy)ì„ ë¶„ì„í•˜ì—¬ ì§€ëŠ¥í˜• ì •ë¦¬ì— í™œìš©
    
    Usage:
        mapper = MapMaker(config)
        tree = mapper.scan("/path/to/root")
        taxonomy = mapper.extract_taxonomy()
        mapper.save_map("directory_map.json")
    """
    
    # íŒŒì¼ ì¹´í…Œê³ ë¦¬ ë§¤í•‘
    CATEGORY_MAP = {
        'documents': {'.pdf', '.docx', '.doc', '.txt', '.md', '.xlsx', '.xls', '.pptx', '.ppt', '.rtf', '.odt'},
        'images': {'.jpg', '.jpeg', '.png', '.gif', '.webp', '.heic', '.bmp', '.svg', '.ico', '.tiff'},
        'videos': {'.mp4', '.mov', '.avi', '.mkv', '.webm', '.flv', '.wmv', '.m4v'},
        'audio': {'.mp3', '.wav', '.flac', '.m4a', '.aac', '.ogg', '.wma'},
        'code': {'.py', '.js', '.ts', '.java', '.cpp', '.c', '.h', '.go', '.rs', '.rb', '.php', '.html', '.css'},
        'archives': {'.zip', '.tar', '.gz', '.7z', '.rar', '.bz2'},
        'data': {'.json', '.xml', '.csv', '.yaml', '.yml', '.sql', '.db'},
        'executables': {'.exe', '.msi', '.dmg', '.app', '.sh', '.bat', '.cmd'},
    }
    
    # ì œì™¸í•  ë””ë ‰í† ë¦¬/íŒŒì¼
    DEFAULT_EXCLUDES = {
        'directories': {'.git', '.svn', 'node_modules', '__pycache__', '.venv', 'venv', '.idea', '.vscode'},
        'files': {'.DS_Store', 'Thumbs.db', 'desktop.ini'},
        'patterns': {'.*', '~$*', '*.tmp', '*.swp'}
    }
    
    def __init__(self, config=None, max_workers: int = 4):
        """
        Args:
            config: AMAA Config ê°ì²´ (optional)
            max_workers: ë³‘ë ¬ ì²˜ë¦¬ ì›Œì»¤ ìˆ˜
        """
        self.config = config
        self.max_workers = max_workers
        
        # ìŠ¤ìº” ê²°ê³¼
        self._root_path: Optional[Path] = None
        self._tree: Optional[DirectoryInfo] = None
        self._all_files: List[FileInfo] = []
        self._all_dirs: List[DirectoryInfo] = []
        
        # í†µê³„
        self._stats = {
            'total_files': 0,
            'total_dirs': 0,
            'total_size': 0,
            'by_category': {},
            'by_extension': {},
            'max_depth': 0,
            'scan_time': 0,
        }
        
        # Taxonomy ë¶„ì„ ê²°ê³¼
        self._taxonomy_patterns: List[TaxonomyPattern] = []
        
        # ì œì™¸ ê·œì¹™ ì„¤ì •
        if config:
            self._excludes = config.exclude
        else:
            self._excludes = self.DEFAULT_EXCLUDES
    
    def scan(self, root_path: str, include_files: bool = True, 
             compute_checksum: bool = False) -> DirectoryInfo:
        """
        ë””ë ‰í† ë¦¬ ì¬ê·€ ìŠ¤ìº” ë° JSON íŠ¸ë¦¬ ìƒì„±
        
        Args:
            root_path: ìŠ¤ìº”í•  ë£¨íŠ¸ ê²½ë¡œ
            include_files: íŒŒì¼ ì •ë³´ í¬í•¨ ì—¬ë¶€
            compute_checksum: íŒŒì¼ ì²´í¬ì„¬ ê³„ì‚° ì—¬ë¶€
            
        Returns:
            DirectoryInfo: ë””ë ‰í† ë¦¬ íŠ¸ë¦¬ êµ¬ì¡°
        """
        start_time = datetime.now()
        
        self._root_path = Path(root_path).expanduser().resolve()
        if not self._root_path.exists():
            raise FileNotFoundError(f"Path not found: {root_path}")
        
        if not self._root_path.is_dir():
            raise NotADirectoryError(f"Not a directory: {root_path}")
        
        # ì´ˆê¸°í™”
        self._all_files.clear()
        self._all_dirs.clear()
        self._stats = {
            'total_files': 0,
            'total_dirs': 0,
            'total_size': 0,
            'by_category': {},
            'by_extension': {},
            'max_depth': 0,
            'scan_time': 0,
        }
        
        # ì¬ê·€ ìŠ¤ìº”
        self._tree = self._scan_directory(
            self._root_path, 
            depth=0,
            include_files=include_files,
            compute_checksum=compute_checksum
        )
        
        # ìŠ¤ìº” ì‹œê°„ ê¸°ë¡
        self._stats['scan_time'] = (datetime.now() - start_time).total_seconds()
        
        return self._tree
    
    def _scan_directory(self, path: Path, depth: int, 
                        include_files: bool, compute_checksum: bool) -> DirectoryInfo:
        """ë””ë ‰í† ë¦¬ ì¬ê·€ ìŠ¤ìº” (ë‚´ë¶€ ë©”ì„œë“œ)"""
        
        dir_info = DirectoryInfo(
            path=str(path),
            name=path.name,
            depth=depth
        )
        
        # ìµœëŒ€ ê¹Šì´ ì—…ë°ì´íŠ¸
        self._stats['max_depth'] = max(self._stats['max_depth'], depth)
        
        try:
            entries = list(path.iterdir())
        except PermissionError:
            return dir_info
        
        subdirs = []
        files = []
        
        for entry in entries:
            # ì œì™¸ ê·œì¹™ ì²´í¬
            if self._should_exclude(entry):
                continue
            
            if entry.is_dir():
                subdirs.append(entry)
            elif entry.is_file():
                files.append(entry)
        
        # í•˜ìœ„ ë””ë ‰í† ë¦¬ ì²˜ë¦¬
        for subdir in subdirs:
            child_info = self._scan_directory(
                subdir, 
                depth + 1, 
                include_files, 
                compute_checksum
            )
            dir_info.children.append(child_info)
            dir_info.dir_count += 1
            dir_info.total_size += child_info.total_size
        
        # íŒŒì¼ ì²˜ë¦¬
        if include_files:
            for file_path in files:
                file_info = self._get_file_info(file_path, depth, compute_checksum)
                dir_info.files.append(file_info)
                dir_info.file_count += 1
                dir_info.total_size += file_info.size
                
                self._all_files.append(file_info)
                self._update_stats(file_info)
        
        self._all_dirs.append(dir_info)
        self._stats['total_dirs'] += 1
        
        return dir_info
    
    def _get_file_info(self, path: Path, depth: int, 
                       compute_checksum: bool) -> FileInfo:
        """íŒŒì¼ ì •ë³´ ì¶”ì¶œ"""
        
        stat_info = path.stat()
        extension = path.suffix.lower()
        
        file_info = FileInfo(
            path=str(path),
            name=path.name,
            extension=extension,
            size=stat_info.st_size,
            created=datetime.fromtimestamp(stat_info.st_ctime).isoformat(),
            modified=datetime.fromtimestamp(stat_info.st_mtime).isoformat(),
            category=self._get_category(extension),
            mime_type=mimetypes.guess_type(str(path))[0],
            is_hidden=path.name.startswith('.'),
            depth=depth
        )
        
        if compute_checksum:
            file_info.checksum = self._compute_checksum(path)
        
        self._stats['total_files'] += 1
        
        return file_info
    
    def _get_category(self, extension: str) -> Optional[str]:
        """í™•ì¥ìë¡œ ì¹´í…Œê³ ë¦¬ ê²°ì •"""
        for category, extensions in self.CATEGORY_MAP.items():
            if extension in extensions:
                return category
        return 'other'
    
    def _compute_checksum(self, path: Path, algorithm: str = 'md5') -> str:
        """íŒŒì¼ ì²´í¬ì„¬ ê³„ì‚°"""
        hash_func = hashlib.new(algorithm)
        
        try:
            with open(path, 'rb') as f:
                for chunk in iter(lambda: f.read(8192), b''):
                    hash_func.update(chunk)
            return hash_func.hexdigest()
        except (PermissionError, OSError):
            return ''
    
    def _should_exclude(self, path: Path) -> bool:
        """ì œì™¸ ê·œì¹™ ì²´í¬"""
        name = path.name
        
        # ë””ë ‰í† ë¦¬ ì œì™¸
        if path.is_dir():
            if name in self._excludes.get('directories', set()):
                return True
        
        # íŒŒì¼ ì œì™¸
        if name in self._excludes.get('files', set()):
            return True
        
        # íŒ¨í„´ ì œì™¸
        import fnmatch
        for pattern in self._excludes.get('patterns', []):
            if fnmatch.fnmatch(name, pattern):
                return True
        
        return False
    
    def _update_stats(self, file_info: FileInfo) -> None:
        """í†µê³„ ì—…ë°ì´íŠ¸"""
        # ì¹´í…Œê³ ë¦¬ë³„ í†µê³„
        category = file_info.category or 'other'
        if category not in self._stats['by_category']:
            self._stats['by_category'][category] = {'count': 0, 'size': 0}
        self._stats['by_category'][category]['count'] += 1
        self._stats['by_category'][category]['size'] += file_info.size
        
        # í™•ì¥ìë³„ í†µê³„
        ext = file_info.extension or 'no_extension'
        if ext not in self._stats['by_extension']:
            self._stats['by_extension'][ext] = {'count': 0, 'size': 0}
        self._stats['by_extension'][ext]['count'] += 1
        self._stats['by_extension'][ext]['size'] += file_info.size
        
        # ì´ í¬ê¸°
        self._stats['total_size'] += file_info.size
    
    def extract_taxonomy(self) -> List[TaxonomyPattern]:
        """
        ì‚¬ìš©ìì˜ ê¸°ì¡´ ë¶„ë¥˜ ìŠµê´€(Taxonomy) ì¶”ì¶œ
        
        ë””ë ‰í† ë¦¬ êµ¬ì¡°ë¥¼ ë¶„ì„í•˜ì—¬ ë°˜ë³µë˜ëŠ” íŒ¨í„´ ì‹ë³„
        
        Returns:
            List[TaxonomyPattern]: ë¶„ë¥˜ ì²´ê³„ íŒ¨í„´ ëª©ë¡
        """
        if not self._tree:
            raise ValueError("Scan first before extracting taxonomy")
        
        self._taxonomy_patterns.clear()
        
        # ë””ë ‰í† ë¦¬ëª… íŒ¨í„´ ë¶„ì„
        dir_names: Dict[str, List[str]] = {}
        for dir_info in self._all_dirs:
            name = dir_info.name.lower()
            
            # ë‚ ì§œ íŒ¨í„´ ì¶”ì¶œ
            if self._is_date_pattern(name):
                pattern = 'date_folder'
            # ë…„ë„ íŒ¨í„´
            elif name.isdigit() and len(name) == 4:
                pattern = 'year_folder'
            # ì¹´í…Œê³ ë¦¬ì„± ì´ë¦„
            elif name in ['documents', 'images', 'videos', 'music', 'downloads', 
                         'ë¬¸ì„œ', 'ì‚¬ì§„', 'ë™ì˜ìƒ', 'ìŒì•…', 'ë‹¤ìš´ë¡œë“œ']:
                pattern = 'category_folder'
            # í”„ë¡œì íŠ¸ì„± ì´ë¦„
            elif '-' in name or '_' in name:
                pattern = 'project_folder'
            else:
                pattern = 'generic_folder'
            
            if pattern not in dir_names:
                dir_names[pattern] = []
            dir_names[pattern].append(dir_info.path)
        
        # íŒ¨í„´ ê°ì²´ ìƒì„±
        for pattern, paths in dir_names.items():
            taxonomy = TaxonomyPattern(
                pattern=pattern,
                count=len(paths),
                examples=paths[:5],  # ìµœëŒ€ 5ê°œ ì˜ˆì‹œ
                depth=self._get_common_depth(paths),
                category_guess=self._guess_category(pattern)
            )
            self._taxonomy_patterns.append(taxonomy)
        
        # íŒŒì¼ëª… íŒ¨í„´ ë¶„ì„
        file_patterns = self._analyze_file_patterns()
        self._taxonomy_patterns.extend(file_patterns)
        
        return self._taxonomy_patterns
    
    def _is_date_pattern(self, name: str) -> bool:
        """ë‚ ì§œ íŒ¨í„´ì¸ì§€ í™•ì¸"""
        import re
        date_patterns = [
            r'\d{4}-\d{2}-\d{2}',  # YYYY-MM-DD
            r'\d{4}_\d{2}_\d{2}',  # YYYY_MM_DD
            r'\d{8}',              # YYYYMMDD
        ]
        return any(re.search(p, name) for p in date_patterns)
    
    def _get_common_depth(self, paths: List[str]) -> int:
        """ê²½ë¡œë“¤ì˜ í‰ê·  ê¹Šì´ ê³„ì‚°"""
        if not paths:
            return 0
        depths = [p.count(os.sep) for p in paths]
        return sum(depths) // len(depths)
    
    def _guess_category(self, pattern: str) -> Optional[str]:
        """íŒ¨í„´ìœ¼ë¡œ ì¹´í…Œê³ ë¦¬ ì¶”ì¸¡"""
        mapping = {
            'date_folder': 'chronological',
            'year_folder': 'chronological',
            'category_folder': 'categorical',
            'project_folder': 'project-based',
            'generic_folder': 'mixed',
        }
        return mapping.get(pattern)
    
    def _analyze_file_patterns(self) -> List[TaxonomyPattern]:
        """íŒŒì¼ëª… íŒ¨í„´ ë¶„ì„"""
        patterns = []
        
        # ë‚ ì§œ ì ‘ë‘ì–´ íŒŒì¼
        date_prefixed = [f for f in self._all_files 
                        if self._is_date_pattern(f.name)]
        if date_prefixed:
            patterns.append(TaxonomyPattern(
                pattern='date_prefixed_files',
                count=len(date_prefixed),
                examples=[f.name for f in date_prefixed[:5]],
                depth=0,
                category_guess='organized'
            ))
        
        # ì¼ê´€ëœ ë„¤ì´ë° íŒ¨í„´ ê°ì§€
        # TODO: ë” ì •êµí•œ íŒ¨í„´ ê°ì§€ ì¶”ê°€
        
        return patterns
    
    def iter_files(self, category: Optional[str] = None) -> Generator[FileInfo, None, None]:
        """
        íŒŒì¼ ì œë„¤ë ˆì´í„° (ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬ìš©)
        
        Args:
            category: íŠ¹ì • ì¹´í…Œê³ ë¦¬ë§Œ í•„í„°ë§ (optional)
            
        Yields:
            FileInfo: íŒŒì¼ ì •ë³´
        """
        for file_info in self._all_files:
            if category is None or file_info.category == category:
                yield file_info
    
    def get_tree(self) -> Optional[DirectoryInfo]:
        """ìŠ¤ìº”ëœ íŠ¸ë¦¬ êµ¬ì¡° ë°˜í™˜"""
        return self._tree
    
    def get_stats(self) -> dict:
        """ìŠ¤ìº” í†µê³„ ë°˜í™˜"""
        return self._stats.copy()
    
    def to_json(self, indent: int = 2) -> str:
        """JSON ë¬¸ìì—´ë¡œ ë³€í™˜"""
        if not self._tree:
            return '{}'
        
        return json.dumps(self._tree.to_dict(), indent=indent, ensure_ascii=False)
    
    def save_map(self, output_path: str) -> None:
        """ë””ë ‰í† ë¦¬ ë§µì„ JSON íŒŒì¼ë¡œ ì €ì¥"""
        path = Path(output_path).expanduser()
        path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(path, 'w', encoding='utf-8') as f:
            f.write(self.to_json())
    
    def load_map(self, input_path: str) -> DirectoryInfo:
        """ì €ì¥ëœ ë””ë ‰í† ë¦¬ ë§µ ë¡œë“œ"""
        path = Path(input_path).expanduser()
        
        with open(path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # TODO: JSONì„ DirectoryInfo ê°ì²´ë¡œ ë³€í™˜
        return data
    
    def get_taxonomy_summary(self) -> str:
        """Taxonomy ìš”ì•½ ë¬¸ìì—´ ìƒì„±"""
        if not self._taxonomy_patterns:
            return "No taxonomy patterns detected"
        
        lines = ["ğŸ“Š Taxonomy Analysis Summary", "=" * 40]
        
        for pattern in sorted(self._taxonomy_patterns, key=lambda x: -x.count):
            lines.append(f"\nğŸ·ï¸ Pattern: {pattern.pattern}")
            lines.append(f"   Count: {pattern.count}")
            lines.append(f"   Category: {pattern.category_guess}")
            lines.append(f"   Examples: {', '.join(pattern.examples[:3])}")
        
        return '\n'.join(lines)
    
    def get_context_for_llm(self, max_depth: int = 3) -> str:
        """
        LLMì—ê²Œ ì „ë‹¬í•  ë””ë ‰í† ë¦¬ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        
        Args:
            max_depth: í¬í•¨í•  ìµœëŒ€ ê¹Šì´
            
        Returns:
            str: LLM í”„ë¡¬í”„íŠ¸ìš© ì»¨í…ìŠ¤íŠ¸
        """
        if not self._tree:
            return "No directory scanned"
        
        lines = [
            f"# Directory Structure: {self._root_path}",
            f"Total Files: {self._stats['total_files']}",
            f"Total Directories: {self._stats['total_dirs']}",
            f"Total Size: {self._format_size(self._stats['total_size'])}",
            "",
            "## Categories:",
        ]
        
        for cat, info in self._stats['by_category'].items():
            lines.append(f"- {cat}: {info['count']} files ({self._format_size(info['size'])})")
        
        lines.append("\n## Directory Tree:")
        lines.append(self._format_tree(self._tree, max_depth=max_depth))
        
        return '\n'.join(lines)
    
    def _format_tree(self, node: DirectoryInfo, prefix: str = "", 
                     max_depth: int = 3) -> str:
        """íŠ¸ë¦¬ êµ¬ì¡° í¬ë§·íŒ…"""
        if node.depth > max_depth:
            return ""
        
        lines = [f"{prefix}ğŸ“ {node.name}/"]
        
        new_prefix = prefix + "  "
        
        # íŒŒì¼
        for f in node.files[:5]:  # ìµœëŒ€ 5ê°œ
            lines.append(f"{new_prefix}ğŸ“„ {f.name}")
        
        if len(node.files) > 5:
            lines.append(f"{new_prefix}... and {len(node.files) - 5} more files")
        
        # í•˜ìœ„ ë””ë ‰í† ë¦¬
        for child in node.children:
            lines.append(self._format_tree(child, new_prefix, max_depth))
        
        return '\n'.join(lines)
    
    def _format_size(self, size: int) -> str:
        """íŒŒì¼ í¬ê¸° í¬ë§·íŒ…"""
        for unit in ['B', 'KB', 'MB', 'GB', 'TB']:
            if size < 1024:
                return f"{size:.1f} {unit}"
            size /= 1024
        return f"{size:.1f} PB"


# ============================================================
# ë³‘ë ¬ ìŠ¤ìº” ë²„ì „ (ëŒ€ê·œëª¨ ë””ë ‰í† ë¦¬ìš©)
# ============================================================

class ParallelMapMaker(MapMaker):
    """
    ë³‘ë ¬ ì²˜ë¦¬ë¥¼ í™œìš©í•œ ê³ ì„±ëŠ¥ ë””ë ‰í† ë¦¬ ì¸ë±ì„œ
    
    ëŒ€ê·œëª¨ ë””ë ‰í† ë¦¬(10ë§Œ+ íŒŒì¼) ìŠ¤ìº”ì— ìµœì í™”
    """
    
    def scan_parallel(self, root_path: str, include_files: bool = True,
                      compute_checksum: bool = False) -> DirectoryInfo:
        """ë³‘ë ¬ ìŠ¤ìº” ì‹¤í–‰"""
        self._root_path = Path(root_path).expanduser().resolve()
        
        # 1ë‹¨ê³„: ë¹ ë¥¸ ë””ë ‰í† ë¦¬ êµ¬ì¡° ìŠ¤ìº”
        dirs_to_scan = self._collect_directories(self._root_path)
        
        # 2ë‹¨ê³„: ë³‘ë ¬ íŒŒì¼ ì •ë³´ ìˆ˜ì§‘
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            futures = {
                executor.submit(self._scan_single_dir, d, include_files, compute_checksum): d
                for d in dirs_to_scan
            }
            
            for future in as_completed(futures):
                try:
                    future.result()
                except Exception as e:
                    print(f"Error scanning: {e}")
        
        # 3ë‹¨ê³„: íŠ¸ë¦¬ êµ¬ì¡° ì¬êµ¬ì„±
        self._tree = self._build_tree_from_scanned()
        
        return self._tree
    
    def _collect_directories(self, root: Path) -> List[Path]:
        """ëª¨ë“  í•˜ìœ„ ë””ë ‰í† ë¦¬ ìˆ˜ì§‘"""
        dirs = [root]
        
        for path in root.rglob('*'):
            if path.is_dir() and not self._should_exclude(path):
                dirs.append(path)
        
        return dirs
    
    def _scan_single_dir(self, path: Path, include_files: bool,
                         compute_checksum: bool) -> None:
        """ë‹¨ì¼ ë””ë ‰í† ë¦¬ ìŠ¤ìº” (ë³‘ë ¬ ì›Œì»¤ìš©)"""
        # ë³‘ë ¬ ì²˜ë¦¬ì—ì„œ ì•ˆì „í•˜ê²Œ íŒŒì¼ ì •ë³´ ìˆ˜ì§‘
        pass
    
    def _build_tree_from_scanned(self) -> DirectoryInfo:
        """ìŠ¤ìº”ëœ ë°ì´í„°ë¡œ íŠ¸ë¦¬ êµ¬ì¡° ë¹Œë“œ"""
        # ìˆ˜ì§‘ëœ ë°ì´í„°ë¡œ íŠ¸ë¦¬ ì¬êµ¬ì„±
        return self._tree


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    import sys
    
    if len(sys.argv) > 1:
        target_path = sys.argv[1]
    else:
        target_path = "."
    
    print(f"ğŸ” Scanning: {target_path}")
    
    mapper = MapMaker()
    tree = mapper.scan(target_path, include_files=True)
    
    print(f"\nğŸ“Š Scan Statistics:")
    stats = mapper.get_stats()
    print(f"  Total Files: {stats['total_files']}")
    print(f"  Total Directories: {stats['total_dirs']}")
    print(f"  Total Size: {mapper._format_size(stats['total_size'])}")
    print(f"  Max Depth: {stats['max_depth']}")
    print(f"  Scan Time: {stats['scan_time']:.2f}s")
    
    print(f"\nğŸ“ Categories:")
    for cat, info in stats['by_category'].items():
        print(f"  {cat}: {info['count']} files")
    
    # Taxonomy ì¶”ì¶œ
    print("\n" + "=" * 50)
    taxonomy = mapper.extract_taxonomy()
    print(mapper.get_taxonomy_summary())
    
    # LLM ì»¨í…ìŠ¤íŠ¸ ì¶œë ¥
    print("\n" + "=" * 50)
    print("ğŸ“ LLM Context:")
    print(mapper.get_context_for_llm(max_depth=2))
